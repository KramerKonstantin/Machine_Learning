# Домашние задания по Machine Learning

## [Codeforces](https://github.com/KramerKonstantin/Machine_Learning/tree/master/codeforces)

### [A. Перекрестная проверка](https://github.com/KramerKonstantin/Machine_Learning/blob/master/codeforces/a.py)

### [B. F-мера](https://github.com/KramerKonstantin/Machine_Learning/blob/master/codeforces/b.py)

### [C. Непараметрическая регрессия](https://github.com/KramerKonstantin/Machine_Learning/blob/master/codeforces/c.py)


## [Labs](https://github.com/KramerKonstantin/Machine_Learning/tree/master/labs)

### [1. kNN](https://github.com/KramerKonstantin/Machine_Learning/tree/master/labs/lab1)
1. Набор данных
Выберите любой понравившийся набор данных для задачи классификации на сайте  openml.org. Выбранный набор данных должен содержать не менее 100 объектов и не менее трёх классов. Запрещено брать набор данных iris! Не забудьте векторизовать признаки вашего набора данных (перейти от категорий к числам), заполнить пропуски (если есть) и нормализовать.

2. Сведение к задаче регрессии
Перейдите от задачи классификации к задаче регрессии двумя разными способами:
* Наивный способ. Каждое значение класса представляется одним числом. Во время предсказания полученный ответ округляется до ближайшего целого числа.
* Используя OneHot преобразование. Вместо одного целевого признака в набор данных добавляется столько новых числовых переменных, сколько в нём содержится классов.

3. Настройка гиперпараметров
Для каждого из преобразований найдите лучшую комбинацию функции расстояния, окна и ядра для метода ближайших соседей. Для лучшего преобразования и найденной комбинации постройте графики зависимости F-меры от числа ближайших соседей или ширины окна. Используйте Leave-One-Out перекрёстную проверку для подсчёта F-меры.

### [2. Linear](https://github.com/KramerKonstantin/Machine_Learning/tree/master/labs/lab2)
1. Задание
Сравните алгоритмы нахождения уравнения прямой:
* Метод наименьших квадратов (псевдообратная матрица / SVD)
* Градиентный спуск
* Генетический алгоритм, либо любой другой алгоритм оптимизации “чёрного ящика” (без использования информации о производной функции)

Для каждого алгоритма найдите наилучшие гиперпараметры (в том числе параметры регуляризации).
Каждый алгоритм следует запускать с различными лимитами времени или итераций. Для каждого алгоритма постройте график зависимости функции ошибки на тренировочном и тестовом множестве от выбранного значения лимита.
В качестве функции ошибки используйте NRMSE, либо SMAPE.

2. Данные
Используйте один из предоставленных наборов данных для тестирования алгоритмов. Каждый тест в архиве организован следующим образом:

> %число признаков%
> %число объектов в тренировочном наборе%
> %объект тренировочного набора 1%
> %объект тренировочного набора 2%
> ...
> %объект тренировочного набора N%
> %число объектов в тестовом наборе%
> %объект тестового набора 1%
> %объект тестового набора 2%
> ...
> %объект тестового набора K%

Формат объектов совпадает с форматом из задачи на codeforces.

### [3. SVM](https://github.com/KramerKonstantin/Machine_Learning/tree/master/labs/lab3)
1. Задание
Реализуйте несколько ядер для метода опорных векторов. Для каждого набора данных и ядра найдите лучшие параметры ядра используя перекрёстную проверку. После нахождения оптимальных параметров для каждого набора данных и ядра нарисуйте, как ваш классификатор классифицирует всё пространство.

2. Набор данных
Используйте наборы данных chips.csv и geyser.csv для тестирования вашего классификатора.

3. Примечание
Не обязательно использовать цвета, можно изобразить контуры разделяющей поверхности, главное чтобы было видно её форму и различимы реальные классы объектов.

### [4. Bayes](https://github.com/KramerKonstantin/Machine_Learning/tree/master/labs/lab4)
1. Задание
Рассмотрим задачу классификации сообщения на спам и на реальные письма.
Придумайте вероятностную модель превращающую письмо в разряженный вектор признаков. Модель должна поддерживать n-граммы и учитывать как заголовок, так и содержание письма.
Постройте ROC кривую для выбранной модели. Посчитайте точность используя перекрестную проверку.
Контролируя веса классов λspam или λlegit , либо априорное распределение добейтесь того, чтобы ни одно реальное сообщение не было классифицировано как спам. Постройте график зависимости точности от выбранного параметра λ, где λ изменяется от значения по умолчанию (λspam = λlegit), до найденного значения в предыдущем пункте.

2. Набор данных
Используйте предоставленный набор данных для тестирования вашего классификатора. Обратите внимание, что это один набор данных разбитый на 10 частей для перекрёстной проверки.

### [5. DT](https://github.com/KramerKonstantin/Machine_Learning/tree/master/labs/lab5)
1. Задание
Для каждого набора данных определите оптимальную высоту дерева принятия решений относительно качества классификации на проверочном множестве. Метрику качества можно брать любую.
Выберите 3 набора данных: набор с минимальной, средней и максимальной  оптимальной высотой. Для трёх выбранных наборов данных нарисуйте график зависимости качества классификации на тренировочном и проверочном множестве от высоты.
Для каждого набора данных постройте лес решающих деревьев на случайном подмножестве признаков и объектов. Сравните результаты классификации для них.

2. Набор данных
Используйте данные наборы данных для тестирования вашего классификатора. Для удобства они также доступны в .txt формате.

### [6. Boost](https://github.com/KramerKonstantin/Machine_Learning/tree/master/labs/lab6)
1. Задание
Изучите алгоритм адаптивного бустинга для задачи классификации с экспоненциальной функцией потерь (AdaBoost). Базовый алгоритм можно использовать любой. Изобразите, как алгоритм классифицирует всё пространство после 1, 2, 3, 5, 8, 13, 21, 34 и 55 шага бустинга. Постройте график зависимости качества от номера шага. Функцию качества можно использовать любую, но вычислять её стоит на каждом шаге, на отдельном тестовом множестве.

2. Набор данных
Используйте наборы данных chips.csv и geyser.csv для тестирования вашего классификатора.

### [7. CNN](https://github.com/KramerKonstantin/Machine_Learning/tree/master/labs/lab7)
1. Задание
Постройте свёрточную “нейронную” сеть, состоящую из последовательности преобразований  свёртки и пулинга. Вывод сети должен завершаться SoftArgMax преобразованием. Попробуйте найти наилучшую архитектуру сети. Для поиска параметров используйте один из методов адаптивного градиентного спуска.
В качестве минимизируемой функции ошибки должна использоваться Перекрёстная Энтропия, а в качестве контрольной функции ошибки - Error Rate. 
Постройте обыкновенную матрицу неточностей, а также матрицу у которой в ячейке i,j находится изображение класса i, которое сеть посчитала наиболее похожим на класс j.

2. Набор данных
Для поиска наилучшей архитектуры используйте набор данных MNIST. Обучите и протестируйте наилучшую найденную архитектуру сети на наборе данных Fashion-MNIST.

### [8. RNN](https://github.com/KramerKonstantin/Machine_Learning/tree/master/labs/lab8)
1. Задание
озьмите какую-нибудь функцию вида y(x) = ∑ai∙sin(bi∙x + ci), где ai,bi,ci некоторые фиксированные параметры (на ваш выбор). Выберите значения xt так, чтобы они равномерно лежали в одном периоде вашей функции. Пусть yt = y(xt).
Используя линейную регрессию постройте алгоритм авторегрессии предсказывающий yt по значениям yt-1, yt-2, yt-3 … yt-k. Также обучите LSTM решать эту задачу.
Постройте график выбранной функции y(x), результатов предсказаний для алгоритмов линейной регрессии и LSTM. Помимо обычного предсказания yt по реальным значениям yt-1, yt-2, yt-3 … yt-k, постройте график предсказания всей функции по первым значениям y1, y2 … yk (алгоритмы должны опираться на собственные предсказания).
Обучите LSTM  предсказывать следующий символ (букву или знак препинания) по предыдущим. Используйте любую доступную книгу для обучения вашей модели. Сравните работу вашего алгоритма в задаче генерации текста (продолжить слово по первым буквам или целое предложение) с обычным автоматом со случайными переходами запоминающим несколько последних букв. В качестве альтернативы можно взять готовые векторные представления слов и строить модели предсказывающие слова целиком.


### [9. Clust](https://github.com/KramerKonstantin/Machine_Learning/tree/master/labs/lab9)
1. Задание
Реализуйте любой алгоритм кластеризации на выбор и две метрики качества кластеризации: одну внешнюю и одну внутреннюю.
Возьмите любой набор данных для задачи классификации, желательно взять  набор данных из лабораторной работы про KNN. Не забудьте векторизовать и нормализовать набор данных.
Нарисуйте два графика: набор данных с реальными метками и с метками полученными в результате кластеризации. Постарайтесь выбрать такие гипер параметры  алгоритма кластеризации, чтобы результат кластеризации был как можно более похож на реальные метки. Для отрисовки многомерных данных используйте преобразование (например PCA), но кластеризацию по прежнему проводите в многомерном пространстве.
Постройте график зависимости выбранных метрик качества кластеризации от числа кластеров.
